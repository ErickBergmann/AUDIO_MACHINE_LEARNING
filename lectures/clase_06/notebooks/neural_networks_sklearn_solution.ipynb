{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usual Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Librosa (the mother of audio files)\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import warnings\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primera actividad independiente\n",
    "\n",
    "Lee las instrucciones y completa los códigos abajo. La idea es realizar los principales pasos asociados al entrenamiento y validación de un modelo clasificador. Por ahora, nos limitaremos a utilizar herramientas e ideas que hemos visto en clases. Progresivamente iremos añadiendo complejidad y nuevas herramientas a este flujo. \n",
    "\n",
    "Para este ejemplo utilizaremos una librería llamada sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop', 'metal', 'disco', 'blues', 'reggae', 'classical', 'rock', 'hiphop', 'country', 'jazz']\n"
     ]
    }
   ],
   "source": [
    "general_path = './data/music_genre'\n",
    "print(list(os.listdir(f'{general_path}/genres_original/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335406</td>\n",
       "      <td>0.091048</td>\n",
       "      <td>0.130405</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>1773.065032</td>\n",
       "      <td>167541.630869</td>\n",
       "      <td>1972.744388</td>\n",
       "      <td>117335.771563</td>\n",
       "      <td>3714.560359</td>\n",
       "      <td>...</td>\n",
       "      <td>39.687145</td>\n",
       "      <td>-3.241280</td>\n",
       "      <td>36.488243</td>\n",
       "      <td>0.722209</td>\n",
       "      <td>38.099152</td>\n",
       "      <td>-5.050335</td>\n",
       "      <td>33.618073</td>\n",
       "      <td>-0.243027</td>\n",
       "      <td>43.771767</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.343065</td>\n",
       "      <td>0.086147</td>\n",
       "      <td>0.112699</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>1816.693777</td>\n",
       "      <td>90525.690866</td>\n",
       "      <td>2010.051501</td>\n",
       "      <td>65671.875673</td>\n",
       "      <td>3869.682242</td>\n",
       "      <td>...</td>\n",
       "      <td>64.748276</td>\n",
       "      <td>-6.055294</td>\n",
       "      <td>40.677654</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>51.264091</td>\n",
       "      <td>-2.837699</td>\n",
       "      <td>97.030830</td>\n",
       "      <td>5.784063</td>\n",
       "      <td>59.943081</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.092243</td>\n",
       "      <td>0.132003</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>1788.539719</td>\n",
       "      <td>111407.437613</td>\n",
       "      <td>2084.565132</td>\n",
       "      <td>75124.921716</td>\n",
       "      <td>3997.639160</td>\n",
       "      <td>...</td>\n",
       "      <td>67.336563</td>\n",
       "      <td>-1.768610</td>\n",
       "      <td>28.348579</td>\n",
       "      <td>2.378768</td>\n",
       "      <td>45.717648</td>\n",
       "      <td>-1.938424</td>\n",
       "      <td>53.050835</td>\n",
       "      <td>2.517375</td>\n",
       "      <td>33.105122</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.363639</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>1655.289045</td>\n",
       "      <td>111952.284517</td>\n",
       "      <td>1960.039988</td>\n",
       "      <td>82913.639269</td>\n",
       "      <td>3568.300218</td>\n",
       "      <td>...</td>\n",
       "      <td>47.739452</td>\n",
       "      <td>-3.841155</td>\n",
       "      <td>28.337118</td>\n",
       "      <td>1.218588</td>\n",
       "      <td>34.770935</td>\n",
       "      <td>-3.580352</td>\n",
       "      <td>50.836224</td>\n",
       "      <td>3.630866</td>\n",
       "      <td>32.023678</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66149</td>\n",
       "      <td>0.335579</td>\n",
       "      <td>0.088129</td>\n",
       "      <td>0.143289</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>1630.656199</td>\n",
       "      <td>79667.267654</td>\n",
       "      <td>1948.503884</td>\n",
       "      <td>60204.020268</td>\n",
       "      <td>3469.992864</td>\n",
       "      <td>...</td>\n",
       "      <td>30.336359</td>\n",
       "      <td>0.664582</td>\n",
       "      <td>45.880913</td>\n",
       "      <td>1.689446</td>\n",
       "      <td>51.363583</td>\n",
       "      <td>-3.392489</td>\n",
       "      <td>26.738789</td>\n",
       "      <td>0.536961</td>\n",
       "      <td>29.146694</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0   66149          0.335406         0.091048  0.130405  0.003521   \n",
       "1   66149          0.343065         0.086147  0.112699  0.001450   \n",
       "2   66149          0.346815         0.092243  0.132003  0.004620   \n",
       "3   66149          0.363639         0.086856  0.132565  0.002448   \n",
       "4   66149          0.335579         0.088129  0.143289  0.001701   \n",
       "\n",
       "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0             1773.065032          167541.630869              1972.744388   \n",
       "1             1816.693777           90525.690866              2010.051501   \n",
       "2             1788.539719          111407.437613              2084.565132   \n",
       "3             1655.289045          111952.284517              1960.039988   \n",
       "4             1630.656199           79667.267654              1948.503884   \n",
       "\n",
       "   spectral_bandwidth_var  rolloff_mean  ...  mfcc16_var  mfcc17_mean  \\\n",
       "0           117335.771563   3714.560359  ...   39.687145    -3.241280   \n",
       "1            65671.875673   3869.682242  ...   64.748276    -6.055294   \n",
       "2            75124.921716   3997.639160  ...   67.336563    -1.768610   \n",
       "3            82913.639269   3568.300218  ...   47.739452    -3.841155   \n",
       "4            60204.020268   3469.992864  ...   30.336359     0.664582   \n",
       "\n",
       "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
       "0   36.488243     0.722209   38.099152    -5.050335   33.618073    -0.243027   \n",
       "1   40.677654     0.159015   51.264091    -2.837699   97.030830     5.784063   \n",
       "2   28.348579     2.378768   45.717648    -1.938424   53.050835     2.517375   \n",
       "3   28.337118     1.218588   34.770935    -3.580352   50.836224     3.630866   \n",
       "4   45.880913     1.689446   51.363583    -3.392489   26.738789     0.536961   \n",
       "\n",
       "   mfcc20_var  label  \n",
       "0   43.771767  blues  \n",
       "1   59.943081  blues  \n",
       "2   33.105122  blues  \n",
       "3   32.023678  blues  \n",
       "4   29.146694  blues  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(f'{general_path}/features_3_sec.csv')\n",
    "data = data.iloc[0:, 1:] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separamos en características y clases en este caso X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['label'] # Género\n",
    "X = data.loc[:, data.columns != 'label'] # Selecciona todas las columnas excepto las clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "blues        1000\n",
       "jazz         1000\n",
       "metal        1000\n",
       "pop          1000\n",
       "reggae       1000\n",
       "disco         999\n",
       "classical     998\n",
       "hiphop        998\n",
       "rock          998\n",
       "country       997\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraemos los nombres de las columnas\n",
    "cols = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer Paso\n",
    "\n",
    "Abre una nueva célula y observa tanto en $X$ como en $y$ los valores utilizando el método de esos objetos llamado ```describe()``` herededo desde ```pandas```. ¿Crees que es necesario escalar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9990.0</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9.990000e+03</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9.990000e+03</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9.990000e+03</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.379534</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>2.676388e-03</td>\n",
       "      <td>2199.219431</td>\n",
       "      <td>4.166727e+05</td>\n",
       "      <td>2241.385959</td>\n",
       "      <td>1.182711e+05</td>\n",
       "      <td>4566.076592</td>\n",
       "      <td>...</td>\n",
       "      <td>1.448240</td>\n",
       "      <td>49.988755</td>\n",
       "      <td>-4.198706</td>\n",
       "      <td>51.962753</td>\n",
       "      <td>0.739943</td>\n",
       "      <td>52.488851</td>\n",
       "      <td>-2.497306</td>\n",
       "      <td>54.973829</td>\n",
       "      <td>-0.917584</td>\n",
       "      <td>57.322614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090466</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>3.585628e-03</td>\n",
       "      <td>751.860611</td>\n",
       "      <td>4.349644e+05</td>\n",
       "      <td>543.854449</td>\n",
       "      <td>1.013505e+05</td>\n",
       "      <td>1642.065335</td>\n",
       "      <td>...</td>\n",
       "      <td>5.735149</td>\n",
       "      <td>34.442816</td>\n",
       "      <td>5.677379</td>\n",
       "      <td>36.400669</td>\n",
       "      <td>5.181313</td>\n",
       "      <td>38.177120</td>\n",
       "      <td>5.111799</td>\n",
       "      <td>41.585677</td>\n",
       "      <td>5.253243</td>\n",
       "      <td>46.444212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.107108</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>4.379535e-08</td>\n",
       "      <td>472.741636</td>\n",
       "      <td>8.118813e+02</td>\n",
       "      <td>499.162910</td>\n",
       "      <td>1.183520e+03</td>\n",
       "      <td>658.336276</td>\n",
       "      <td>...</td>\n",
       "      <td>-26.850016</td>\n",
       "      <td>1.325786</td>\n",
       "      <td>-27.809795</td>\n",
       "      <td>1.624544</td>\n",
       "      <td>-20.733809</td>\n",
       "      <td>3.437439</td>\n",
       "      <td>-27.448456</td>\n",
       "      <td>3.065302</td>\n",
       "      <td>-35.640659</td>\n",
       "      <td>0.282131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.315698</td>\n",
       "      <td>0.079833</td>\n",
       "      <td>0.083782</td>\n",
       "      <td>6.145900e-04</td>\n",
       "      <td>1630.680158</td>\n",
       "      <td>1.231961e+05</td>\n",
       "      <td>1887.455790</td>\n",
       "      <td>4.876553e+04</td>\n",
       "      <td>3378.311110</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.227478</td>\n",
       "      <td>29.584894</td>\n",
       "      <td>-7.951722</td>\n",
       "      <td>29.863448</td>\n",
       "      <td>-2.516638</td>\n",
       "      <td>29.636197</td>\n",
       "      <td>-5.734123</td>\n",
       "      <td>30.496412</td>\n",
       "      <td>-4.004475</td>\n",
       "      <td>30.011365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.384741</td>\n",
       "      <td>0.085108</td>\n",
       "      <td>0.121253</td>\n",
       "      <td>1.491318e-03</td>\n",
       "      <td>2208.628236</td>\n",
       "      <td>2.650692e+05</td>\n",
       "      <td>2230.575595</td>\n",
       "      <td>8.996072e+04</td>\n",
       "      <td>4631.377892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.461623</td>\n",
       "      <td>41.702393</td>\n",
       "      <td>-4.443021</td>\n",
       "      <td>42.393583</td>\n",
       "      <td>0.733772</td>\n",
       "      <td>41.831377</td>\n",
       "      <td>-2.702366</td>\n",
       "      <td>43.435253</td>\n",
       "      <td>-1.030939</td>\n",
       "      <td>44.332155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.442443</td>\n",
       "      <td>0.091092</td>\n",
       "      <td>0.176328</td>\n",
       "      <td>3.130862e-03</td>\n",
       "      <td>2712.581884</td>\n",
       "      <td>5.624152e+05</td>\n",
       "      <td>2588.340505</td>\n",
       "      <td>1.585674e+05</td>\n",
       "      <td>5591.634521</td>\n",
       "      <td>...</td>\n",
       "      <td>5.149752</td>\n",
       "      <td>59.274619</td>\n",
       "      <td>-0.726945</td>\n",
       "      <td>61.676964</td>\n",
       "      <td>3.888734</td>\n",
       "      <td>62.033906</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>65.328602</td>\n",
       "      <td>2.216603</td>\n",
       "      <td>68.210421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>66149.0</td>\n",
       "      <td>0.749481</td>\n",
       "      <td>0.120964</td>\n",
       "      <td>0.442567</td>\n",
       "      <td>3.261522e-02</td>\n",
       "      <td>5432.534406</td>\n",
       "      <td>4.794119e+06</td>\n",
       "      <td>3708.147554</td>\n",
       "      <td>1.235143e+06</td>\n",
       "      <td>9487.446477</td>\n",
       "      <td>...</td>\n",
       "      <td>39.144405</td>\n",
       "      <td>683.932556</td>\n",
       "      <td>34.048843</td>\n",
       "      <td>529.363342</td>\n",
       "      <td>36.970322</td>\n",
       "      <td>629.729797</td>\n",
       "      <td>31.365425</td>\n",
       "      <td>1143.230591</td>\n",
       "      <td>34.212101</td>\n",
       "      <td>910.473206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        length  chroma_stft_mean  chroma_stft_var     rms_mean       rms_var  \\\n",
       "count   9990.0       9990.000000      9990.000000  9990.000000  9.990000e+03   \n",
       "mean   66149.0          0.379534         0.084876     0.130859  2.676388e-03   \n",
       "std        0.0          0.090466         0.009637     0.068545  3.585628e-03   \n",
       "min    66149.0          0.107108         0.015345     0.000953  4.379535e-08   \n",
       "25%    66149.0          0.315698         0.079833     0.083782  6.145900e-04   \n",
       "50%    66149.0          0.384741         0.085108     0.121253  1.491318e-03   \n",
       "75%    66149.0          0.442443         0.091092     0.176328  3.130862e-03   \n",
       "max    66149.0          0.749481         0.120964     0.442567  3.261522e-02   \n",
       "\n",
       "       spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "count             9990.000000           9.990000e+03              9990.000000   \n",
       "mean              2199.219431           4.166727e+05              2241.385959   \n",
       "std                751.860611           4.349644e+05               543.854449   \n",
       "min                472.741636           8.118813e+02               499.162910   \n",
       "25%               1630.680158           1.231961e+05              1887.455790   \n",
       "50%               2208.628236           2.650692e+05              2230.575595   \n",
       "75%               2712.581884           5.624152e+05              2588.340505   \n",
       "max               5432.534406           4.794119e+06              3708.147554   \n",
       "\n",
       "       spectral_bandwidth_var  rolloff_mean  ...  mfcc16_mean   mfcc16_var  \\\n",
       "count            9.990000e+03   9990.000000  ...  9990.000000  9990.000000   \n",
       "mean             1.182711e+05   4566.076592  ...     1.448240    49.988755   \n",
       "std              1.013505e+05   1642.065335  ...     5.735149    34.442816   \n",
       "min              1.183520e+03    658.336276  ...   -26.850016     1.325786   \n",
       "25%              4.876553e+04   3378.311110  ...    -2.227478    29.584894   \n",
       "50%              8.996072e+04   4631.377892  ...     1.461623    41.702393   \n",
       "75%              1.585674e+05   5591.634521  ...     5.149752    59.274619   \n",
       "max              1.235143e+06   9487.446477  ...    39.144405   683.932556   \n",
       "\n",
       "       mfcc17_mean   mfcc17_var  mfcc18_mean   mfcc18_var  mfcc19_mean  \\\n",
       "count  9990.000000  9990.000000  9990.000000  9990.000000  9990.000000   \n",
       "mean     -4.198706    51.962753     0.739943    52.488851    -2.497306   \n",
       "std       5.677379    36.400669     5.181313    38.177120     5.111799   \n",
       "min     -27.809795     1.624544   -20.733809     3.437439   -27.448456   \n",
       "25%      -7.951722    29.863448    -2.516638    29.636197    -5.734123   \n",
       "50%      -4.443021    42.393583     0.733772    41.831377    -2.702366   \n",
       "75%      -0.726945    61.676964     3.888734    62.033906     0.514246   \n",
       "max      34.048843   529.363342    36.970322   629.729797    31.365425   \n",
       "\n",
       "        mfcc19_var  mfcc20_mean   mfcc20_var  \n",
       "count  9990.000000  9990.000000  9990.000000  \n",
       "mean     54.973829    -0.917584    57.322614  \n",
       "std      41.585677     5.253243    46.444212  \n",
       "min       3.065302   -35.640659     0.282131  \n",
       "25%      30.496412    -4.004475    30.011365  \n",
       "50%      43.435253    -1.030939    44.332155  \n",
       "75%      65.328602     2.216603    68.210421  \n",
       "max    1143.230591    34.212101   910.473206  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count      9990\n",
       "unique       10\n",
       "top       blues\n",
       "freq       1000\n",
       "Name: label, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la libería ```sklearn``` importamos ```preprocessing```. Utiliza ```help(preprocessing.MinMaxScaler())``` para entender como utilizar el método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MinMaxScaler in module sklearn.preprocessing._data object:\n",
      "\n",
      "class MinMaxScaler(sklearn.base.OneToOneFeatureMixin, sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  MinMaxScaler(feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |  \n",
      " |  Transform features by scaling each feature to a given range.\n",
      " |  \n",
      " |  This estimator scales and translates each feature individually such\n",
      " |  that it is in the given range on the training set, e.g. between\n",
      " |  zero and one.\n",
      " |  \n",
      " |  The transformation is given by::\n",
      " |  \n",
      " |      X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
      " |      X_scaled = X_std * (max - min) + min\n",
      " |  \n",
      " |  where min, max = feature_range.\n",
      " |  \n",
      " |  This transformation is often used as an alternative to zero mean,\n",
      " |  unit variance scaling.\n",
      " |  \n",
      " |  `MinMaxScaler` doesn't reduce the effect of outliers, but it linearily\n",
      " |  scales them down into a fixed range, where the largest occuring data point\n",
      " |  corresponds to the maximum value and the smallest one corresponds to the\n",
      " |  minimum value. For an example visualization, refer to :ref:`Compare\n",
      " |  MinMaxScaler with other scalers <plot_all_scaling_minmax_scaler_section>`.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  feature_range : tuple (min, max), default=(0, 1)\n",
      " |      Desired range of transformed data.\n",
      " |  \n",
      " |  copy : bool, default=True\n",
      " |      Set to False to perform inplace row normalization and avoid a\n",
      " |      copy (if the input is already a numpy array).\n",
      " |  \n",
      " |  clip : bool, default=False\n",
      " |      Set to True to clip transformed values of held-out data to\n",
      " |      provided `feature range`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  min_ : ndarray of shape (n_features,)\n",
      " |      Per feature adjustment for minimum. Equivalent to\n",
      " |      ``min - X.min(axis=0) * self.scale_``\n",
      " |  \n",
      " |  scale_ : ndarray of shape (n_features,)\n",
      " |      Per feature relative scaling of the data. Equivalent to\n",
      " |      ``(max - min) / (X.max(axis=0) - X.min(axis=0))``\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_* attribute.\n",
      " |  \n",
      " |  data_min_ : ndarray of shape (n_features,)\n",
      " |      Per feature minimum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_min_*\n",
      " |  \n",
      " |  data_max_ : ndarray of shape (n_features,)\n",
      " |      Per feature maximum seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_max_*\n",
      " |  \n",
      " |  data_range_ : ndarray of shape (n_features,)\n",
      " |      Per feature range ``(data_max_ - data_min_)`` seen in the data\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *data_range_*\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  n_samples_seen_ : int\n",
      " |      The number of samples processed by the estimator.\n",
      " |      It will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  minmax_scale : Equivalent function without the estimator API.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import MinMaxScaler\n",
      " |  >>> data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
      " |  >>> scaler = MinMaxScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  MinMaxScaler()\n",
      " |  >>> print(scaler.data_max_)\n",
      " |  [ 1. 18.]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[0.   0.  ]\n",
      " |   [0.25 0.25]\n",
      " |   [0.5  0.5 ]\n",
      " |   [1.   1.  ]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[1.5 0. ]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MinMaxScaler\n",
      " |      sklearn.base.OneToOneFeatureMixin\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.utils._set_output._SetOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, feature_range=(0, 1), *, copy=True, clip=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the minimum and maximum to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the per-feature minimum and maximum\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  inverse_transform(self, X)\n",
      " |      Undo the scaling of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed. It cannot be sparse.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of min and max on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Fitted scaler.\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Scale features of X according to feature_range.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input data that will be transformed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      Xt : ndarray of shape (n_samples, n_features)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  get_feature_names_out(self, input_features=None)\n",
      " |      Get output feature names for transformation.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      input_features : array-like of str or None, default=None\n",
      " |          Input features.\n",
      " |      \n",
      " |          - If `input_features` is `None`, then `feature_names_in_` is\n",
      " |            used as feature names in. If `feature_names_in_` is not defined,\n",
      " |            then the following input feature names are generated:\n",
      " |            `[\"x0\", \"x1\", ..., \"x(n_features_in_ - 1)\"]`.\n",
      " |          - If `input_features` is an array-like, then `input_features` must\n",
      " |            match `feature_names_in_` if `feature_names_in_` is defined.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_names_out : ndarray of str objects\n",
      " |          Same as input features.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.OneToOneFeatureMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to `X` and `y` with optional parameters `fit_params`\n",
      " |      and returns a transformed version of `X`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Input samples.\n",
      " |      \n",
      " |      y :  array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None\n",
      " |          Target values (None for unsupervised transformations).\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  set_output(self, *, transform=None)\n",
      " |      Set output container.\n",
      " |      \n",
      " |      See :ref:`sphx_glr_auto_examples_miscellaneous_plot_set_output.py`\n",
      " |      for an example on how to use the API.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      transform : {\"default\", \"pandas\"}, default=None\n",
      " |          Configure output of `transform` and `fit_transform`.\n",
      " |      \n",
      " |          - `\"default\"`: Default output format of a transformer\n",
      " |          - `\"pandas\"`: DataFrame output\n",
      " |          - `None`: Transform configuration is unchanged\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._set_output._SetOutputMixin:\n",
      " |  \n",
      " |  __init_subclass__(auto_wrap_output_keys=('transform',), **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |      Helper for pickle.\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(preprocessing.MinMaxScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, instancia el escalador de datos con ```min_max_scaler = preprocessing.MinMaxScaler()```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Aqui instancia el escalador de datos\n",
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, escala tus datos a través del método de clase de tu ```min_max_scaler``` llamado ```.fit_transform()```\n",
    "Este método recibe como entrada tus datos $X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Escala tus datos aquí\n",
    "np_scaled = min_max_scaler.fit_transform(X)\n",
    "### Convertimos la data en una tabla estructurada\n",
    "X = pd.DataFrame(np_scaled, columns = cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza nuevamente la función ```describe()``` sobre $X$ para confirmar el escalamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>rolloff_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_mean</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9990.0</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "      <td>9990.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424094</td>\n",
       "      <td>0.658319</td>\n",
       "      <td>0.294161</td>\n",
       "      <td>0.082058</td>\n",
       "      <td>0.348095</td>\n",
       "      <td>0.086759</td>\n",
       "      <td>0.542920</td>\n",
       "      <td>0.094888</td>\n",
       "      <td>0.442597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428798</td>\n",
       "      <td>0.071290</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.095385</td>\n",
       "      <td>0.372135</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>0.424239</td>\n",
       "      <td>0.045527</td>\n",
       "      <td>0.497090</td>\n",
       "      <td>0.062669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140831</td>\n",
       "      <td>0.091239</td>\n",
       "      <td>0.155216</td>\n",
       "      <td>0.109937</td>\n",
       "      <td>0.151591</td>\n",
       "      <td>0.090744</td>\n",
       "      <td>0.169479</td>\n",
       "      <td>0.082134</td>\n",
       "      <td>0.185983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086904</td>\n",
       "      <td>0.050458</td>\n",
       "      <td>0.091780</td>\n",
       "      <td>0.068975</td>\n",
       "      <td>0.089791</td>\n",
       "      <td>0.060957</td>\n",
       "      <td>0.086915</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.075205</td>\n",
       "      <td>0.051027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324718</td>\n",
       "      <td>0.610570</td>\n",
       "      <td>0.187559</td>\n",
       "      <td>0.018842</td>\n",
       "      <td>0.233465</td>\n",
       "      <td>0.025532</td>\n",
       "      <td>0.432627</td>\n",
       "      <td>0.038560</td>\n",
       "      <td>0.308069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.373100</td>\n",
       "      <td>0.041399</td>\n",
       "      <td>0.321023</td>\n",
       "      <td>0.053509</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.041832</td>\n",
       "      <td>0.369204</td>\n",
       "      <td>0.024059</td>\n",
       "      <td>0.452898</td>\n",
       "      <td>0.032663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432199</td>\n",
       "      <td>0.660514</td>\n",
       "      <td>0.272410</td>\n",
       "      <td>0.045723</td>\n",
       "      <td>0.349992</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.539552</td>\n",
       "      <td>0.071945</td>\n",
       "      <td>0.449993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.059151</td>\n",
       "      <td>0.377745</td>\n",
       "      <td>0.077252</td>\n",
       "      <td>0.372028</td>\n",
       "      <td>0.061304</td>\n",
       "      <td>0.420753</td>\n",
       "      <td>0.035407</td>\n",
       "      <td>0.495467</td>\n",
       "      <td>0.048396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.522026</td>\n",
       "      <td>0.717174</td>\n",
       "      <td>0.397122</td>\n",
       "      <td>0.095993</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.117164</td>\n",
       "      <td>0.651040</td>\n",
       "      <td>0.127544</td>\n",
       "      <td>0.558754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484886</td>\n",
       "      <td>0.084893</td>\n",
       "      <td>0.437818</td>\n",
       "      <td>0.113792</td>\n",
       "      <td>0.426703</td>\n",
       "      <td>0.093561</td>\n",
       "      <td>0.475444</td>\n",
       "      <td>0.054609</td>\n",
       "      <td>0.541958</td>\n",
       "      <td>0.074631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       length  chroma_stft_mean  chroma_stft_var     rms_mean      rms_var  \\\n",
       "count  9990.0       9990.000000      9990.000000  9990.000000  9990.000000   \n",
       "mean      0.0          0.424094         0.658319     0.294161     0.082058   \n",
       "std       0.0          0.140831         0.091239     0.155216     0.109937   \n",
       "min       0.0          0.000000         0.000000     0.000000     0.000000   \n",
       "25%       0.0          0.324718         0.610570     0.187559     0.018842   \n",
       "50%       0.0          0.432199         0.660514     0.272410     0.045723   \n",
       "75%       0.0          0.522026         0.717174     0.397122     0.095993   \n",
       "max       0.0          1.000000         1.000000     1.000000     1.000000   \n",
       "\n",
       "       spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "count             9990.000000            9990.000000              9990.000000   \n",
       "mean                 0.348095               0.086759                 0.542920   \n",
       "std                  0.151591               0.090744                 0.169479   \n",
       "min                  0.000000               0.000000                 0.000000   \n",
       "25%                  0.233465               0.025532                 0.432627   \n",
       "50%                  0.349992               0.055130                 0.539552   \n",
       "75%                  0.451600               0.117164                 0.651040   \n",
       "max                  1.000000               1.000000                 1.000000   \n",
       "\n",
       "       spectral_bandwidth_var  rolloff_mean  ...  mfcc16_mean   mfcc16_var  \\\n",
       "count             9990.000000   9990.000000  ...  9990.000000  9990.000000   \n",
       "mean                 0.094888      0.442597  ...     0.428798     0.071290   \n",
       "std                  0.082134      0.185983  ...     0.086904     0.050458   \n",
       "min                  0.000000      0.000000  ...     0.000000     0.000000   \n",
       "25%                  0.038560      0.308069  ...     0.373100     0.041399   \n",
       "50%                  0.071945      0.449993  ...     0.429000     0.059151   \n",
       "75%                  0.127544      0.558754  ...     0.484886     0.084893   \n",
       "max                  1.000000      1.000000  ...     1.000000     1.000000   \n",
       "\n",
       "       mfcc17_mean   mfcc17_var  mfcc18_mean   mfcc18_var  mfcc19_mean  \\\n",
       "count  9990.000000  9990.000000  9990.000000  9990.000000  9990.000000   \n",
       "mean      0.381694     0.095385     0.372135     0.078320     0.424239   \n",
       "std       0.091780     0.068975     0.089791     0.060957     0.086915   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.321023     0.053509     0.315700     0.041832     0.369204   \n",
       "50%       0.377745     0.077252     0.372028     0.061304     0.420753   \n",
       "75%       0.437818     0.113792     0.426703     0.093561     0.475444   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "        mfcc19_var  mfcc20_mean   mfcc20_var  \n",
       "count  9990.000000  9990.000000  9990.000000  \n",
       "mean      0.045527     0.497090     0.062669  \n",
       "std       0.036473     0.075205     0.051027  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.024059     0.452898     0.032663  \n",
       "50%       0.035407     0.495467     0.048396  \n",
       "75%       0.054609     0.541958     0.074631  \n",
       "max       1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora divide en entrenamiento y test el conjunto de datos. Utiliza ```help(train_test_split)``` y divide los datos con un ```test_size=0.3``` y un ```random_state = 42``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
      "    Split arrays or matrices into random train and test subsets.\n",
      "    \n",
      "    Quick utility that wraps input validation,\n",
      "    ``next(ShuffleSplit().split(X, y))``, and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data into a\n",
      "    one-liner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "        Read more in the :ref:`User Guide <stratification>`.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.3, random_state=  42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los modelos revisados en clase para clasificar y las métricas para evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression #regresión logística\n",
    "from sklearn.neural_network import MLPClassifier    #perceptrón multicapa\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score # matriz de confusión y accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completa la siguiente clase con la información faltante\n",
    "\n",
    "Observa que ```hidden_layer_sizes``` representa un modelo de dos capas una con dimension 500 y otra con dimension 10. La dimensión de entrada dependerá del número de características, en este caso 59 características dadas por el dataset. \n",
    "Por lo tanto las matrices serán de $59 \\times 500$ y $500 \\times 10$. La ùltima capa será de $10 \\times \\text{numero de clases}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiPrimeraRed:\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes=(500, 10), alpha=1e-3, solver='sgd', max_iter = 1000):\n",
    "        ### COMPLETA ESTOS ATRIBUTOS\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes  #número de capas escondidas\n",
    "        self.alpha = alpha #learning rate\n",
    "        self.solver = solver #optimizador, por ahora utilizaremos el que conocemos Gradiente Estocástico\n",
    "        self.max_iter = max_iter\n",
    "        ### INICIALIZAMOS EL PERCEPTRON MULTICAPA\n",
    "        self.nn = MLPClassifier(solver= self.solver, \n",
    "                                alpha=self.alpha, \n",
    "                                hidden_layer_sizes = self.hidden_layer_sizes, \n",
    "                                max_iter = self.max_iter ,\n",
    "                                random_state=1)\n",
    "        \n",
    "    def train_model(self, X_train, y_train):\n",
    "        try:\n",
    "            self.nn.fit(X_train,y_train)\n",
    "            print(\"Modelo entrenado exitosamente!\")\n",
    "        except Exception as e:\n",
    "            print(f\"Algo ha ocurrido al momento de entrenar: {e}\")\n",
    "\n",
    "    def measuring_model_accuracy(self, X_test, y_test):\n",
    "        # confirmamos que el modelo ya fue entrenado para poder medir accuracy\n",
    "        if hasattr(self.nn, 'coefs_'):\n",
    "            preds = self.nn.predict(X_test)\n",
    "            print('Accuracy', accuracy_score(y_test, preds), '\\n')\n",
    "            print(\"Matriz de Confusión\")\n",
    "            print(confusion_matrix(y_test, preds))\n",
    "        else:\n",
    "            print('El modelo no ha sido entrenado, no es posible medir accuracy')\n",
    "            \n",
    "    def summary(self):\n",
    "        # Print model configuration\n",
    "        print(\"Model Configuration:\")\n",
    "        print(f\"Hidden Layer Sizes: {self.hidden_layer_sizes}\")\n",
    "        print(f\"Alpha (Learning Rate): {self.alpha}\")\n",
    "        print(f\"Solver (Optimizer): {self.solver}\")\n",
    "        print(f\"Max Iterations: {self.max_iter}\")\n",
    "\n",
    "        # Check if the model has been trained\n",
    "        if hasattr(self.nn, 'coefs_'):\n",
    "            print(\"\\nTraining Summary:\")\n",
    "            \n",
    "            # Print the number of iterations\n",
    "            print(f\"Number of Iterations: {self.nn.n_iter_}\")\n",
    "            \n",
    "            # Print the loss\n",
    "            print(f\"Loss: {self.nn.loss_:.4f}\")\n",
    "            \n",
    "            # Print the configuration of each layer\n",
    "            for i, (coef, intercept) in enumerate(zip(self.nn.coefs_, self.nn.intercepts_), start=1):\n",
    "                print(f\"Layer {i}:\")\n",
    "                print(f\" - Weights shape: {coef.shape}\")\n",
    "                print(f\" - Biases shape: {intercept.shape}\")\n",
    "            \n",
    "            # Optionally, you could add performance metrics (e.g., accuracy, confusion matrix, classification report)\n",
    "            # You would need to store X_test and y_test as attributes of the class after measuring_model_accuracy is called\n",
    "            # to be able to reference them here.\n",
    "        else:\n",
    "            print('The model has not been trained yet.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora instancia tu modelo, entrenalo y evalúalo utilizando los métodos dentro de las clases!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_modelo = MiPrimeraRed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo entrenado exitosamente!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodolfolobocarrasco/.pyenv/versions/3.11.6/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "mi_modelo.train_model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7380714047380714 \n",
      "\n",
      "Matriz de Confusión\n",
      "[[230   2  17   8   3  17  20   0  10  12]\n",
      " [  1 290   2   0   0  14   0   0   0   1]\n",
      " [ 14   2 183   7   0  20   2  13   6  39]\n",
      " [  2   3  10 190  12   5   9  20  20  30]\n",
      " [ 12   2   4  13 221   0  11  15  30   3]\n",
      " [  4  26   6   0   0 243   0   2   5   0]\n",
      " [  9   0   4   4   6   1 265   0   1  13]\n",
      " [  2   0   9   8   3   0   0 235   7   3]\n",
      " [  6   1  15  10  25   5   3  12 231   8]\n",
      " [ 16   7  34  46   3  20  19  14  17 124]]\n"
     ]
    }
   ],
   "source": [
    "mi_modelo.measuring_model_accuracy(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Configuration:\n",
      "Hidden Layer Sizes: (500, 10)\n",
      "Alpha (Learning Rate): 0.001\n",
      "Solver (Optimizer): sgd\n",
      "Max Iterations: 1000\n",
      "\n",
      "Training Summary:\n",
      "Number of Iterations: 1000\n",
      "Loss: 0.7041\n",
      "Layer 1:\n",
      " - Weights shape: (58, 500)\n",
      " - Biases shape: (500,)\n",
      "Layer 2:\n",
      " - Weights shape: (500, 10)\n",
      " - Biases shape: (10,)\n",
      "Layer 3:\n",
      " - Weights shape: (10, 10)\n",
      " - Biases shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "mi_modelo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe la clase original de ```MLPClassifier``` [Link](https://github.com/scikit-learn/scikit-learn/blob/093e0cf14aff026cca6097e8c42f83b735d26358/sklearn/neural_network/_multilayer_perceptron.py#L382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=(500, 10), max_iter=1000,\n",
       "              random_state=1, solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=(500, 10), max_iter=1000,\n",
       "              random_state=1, solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(alpha=0.001, hidden_layer_sizes=(500, 10), max_iter=1000,\n",
       "              random_state=1, solver='sgd')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mi_modelo.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate target 9\n",
      "True\n",
      "0 1\n",
      "response {0: {0, 1}}\n",
      "candidate target 13\n",
      "candidate target 17\n",
      "candidate target 9\n",
      "True\n",
      "1 0\n",
      "candidate target 18\n",
      "candidate target 22\n",
      "candidate target 13\n",
      "candidate target 18\n",
      "candidate target 26\n",
      "candidate target 17\n",
      "candidate target 22\n",
      "candidate target 26\n"
     ]
    }
   ],
   "source": [
    "class Solution(object):\n",
    "    def twoSum(self, nums, target):\n",
    "        \"\"\"\n",
    "        :type nums: List[int]\n",
    "        :type target: int\n",
    "        :rtype: List[int]\n",
    "        \"\"\"\n",
    "        response = {}\n",
    "        key = 0\n",
    "        for i, ref in enumerate(nums):\n",
    "            for j, num in enumerate(nums):\n",
    "                if i != j:\n",
    "                    candidate_target = num + ref\n",
    "                    print(\"candidate target\", candidate_target)\n",
    "                    if candidate_target == target:\n",
    "                        print(candidate_target == target)\n",
    "                        print(i,j)\n",
    "                        if set([i,j]) not in response.values():\n",
    "                            response[key]=set([i,j])\n",
    "                            key =+ 1\n",
    "                            print(\"response\", response)\n",
    "        output = list()\n",
    "        \n",
    "        for e in response.values():\n",
    "            output.append(e)\n",
    "        return output\n",
    "\n",
    "nums = [2,7,11,15]\n",
    "target = 9\n",
    "my_class = Solution()\n",
    "output = my_class.twoSum(nums, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{0, 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
